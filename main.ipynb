{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd0b7365d69f22ee809fd7080e4c360f70b239ec95a60ded2c1c06e00fccc56a2ce",
   "display_name": "Python 3.8.6rc1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SpeechLib import Sound_Clip, speech_recon_utils\n",
    "import numpy as np\n",
    "from PattRecClasses import DiscreteD, GaussD, HMM, MarkovChain, GMM\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import threading\n",
    "import scipy.stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nfor subdirs, dir, files in os.walk(train_dir):\\n  obs = np.zeros(shape=(40, 13, zero_max_dim))# len(files)\\n  counter = 0\\n  for file in files:\\n    temp = Sound_Clip(train_dir+file)\\n    temp = temp.mfcc(nceps=13,wintime=0.03, overlap=0.5, winfunc=np.hanning, lowfreq=0,highfreq=4000, nbands=30)\\n    temp = speech_recon_utils.CVMN(temp)\\n    if temp.shape[0] < zero_max_dim:\\n        temp = np.append(temp, np.tile(temp[-1,:],(zero_max_dim-temp.shape[0],1)), axis=0)\\n    \\n    obs[counter, :, :] = temp.T\\n    counter = counter + 1\\n    if counter == 40:\\n        break\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "max_dim = 66\n",
    "train_dir = './Sounds/train2/0/'\n",
    "\n",
    "for subdirs, dir, files in os.walk(train_dir):\n",
    "  obs = np.zeros(shape=(len(files), 13, max_dim))# len(files)\n",
    "  counter = 0\n",
    "  for file in files:\n",
    "    temp = Sound_Clip(train_dir+file)\n",
    "    temp = temp.mfcc(nceps=13,wintime=0.03, overlap=0.5, winfunc=np.hanning, lowfreq=0,highfreq=4000, nbands=30)\n",
    "    temp = speech_recon_utils.CVMN(temp)\n",
    "    if temp.shape[0] < max_dim:\n",
    "        temp = np.append(temp, np.tile(temp[-1,:],(max_dim-temp.shape[0],1)), axis=0)\n",
    "    \n",
    "    obs[counter, :, :] = temp.T\n",
    "    counter = counter + 1\n",
    "\"\"\"\n",
    "for subdirs, dir, files in os.walk(train_dir):\n",
    "  obs = np.zeros(shape=(40, 13, zero_max_dim))# len(files)\n",
    "  counter = 0\n",
    "  for file in files:\n",
    "    temp = Sound_Clip(train_dir+file)\n",
    "    temp = temp.mfcc(nceps=13,wintime=0.03, overlap=0.5, winfunc=np.hanning, lowfreq=0,highfreq=4000, nbands=30)\n",
    "    temp = speech_recon_utils.CVMN(temp)\n",
    "    if temp.shape[0] < zero_max_dim:\n",
    "        temp = np.append(temp, np.tile(temp[-1,:],(zero_max_dim-temp.shape[0],1)), axis=0)\n",
    "    \n",
    "    obs[counter, :, :] = temp.T\n",
    "    counter = counter + 1\n",
    "    if counter == 40:\n",
    "        break\n",
    "\"\"\"\n",
    "#obs = recording_features\n",
    "# 0: maximum time 66\n",
    "# 1: maximum time 63\n",
    "# 2: maximum time 56\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# zero\t\tz iy r ow \n",
    "# one   \tw ah n\n",
    "# two\t\t\tt uw\n",
    "# three\t\tth r iy\n",
    "# four\t\tf ao r\n",
    "# five\t\tf ay v\n",
    "# six\t\t\ts ih k s\n",
    "# seven   s eh v ax n\n",
    "# eight   ey t\n",
    "# nine\t\tn ay n\n",
    "\n",
    "# possible states = [silence, z, iy, r, ow, w, ah, n, t, uw, th, f, ai, ay, v, s, ih, k\n",
    "# \t\t\t\t\t\t\t\t\t\tehm ax, n, ey]\n",
    "means = np.zeros(13)\n",
    "covs = np.ones(13)\n",
    "#means = np.array([[0] for _ in np.arange(13)])\n",
    "#covs = np.array([[1] for _ in np.arange(13)])\n",
    "weights = np.random.rand(13)\n",
    "weights = weights/ np.sum(weights)\n",
    "q = np.array([1,1,1,1,1])/5\n",
    "A = np.array([[0.5,0.5,0,0,0,0],[0,0.5,0.5,0,0,0],[0,0,0.5,0.5,0,0],[0,0,0,0.5,0.5,0],[0,0,0,0,0.5,0.5]])\n",
    "B = np.array([GMM(means,covs, weights) for i in np.arange(5)])\n",
    "\n",
    "\n",
    "mc = MarkovChain(q,A)\n",
    "hmm = HMM(mc, B)\n",
    "print('Baum_Welch')\n",
    "\"\"\"\n",
    "\n",
    "means = np.zeros(13)\n",
    "covs = np.ones(13)\n",
    "weights = np.random.rand(13)\n",
    "weights = weights/ np.sum(weights)\n",
    "q = np.array([1,1,1,1,1,1])/6\n",
    "A = np.array([[0.5,0.5,0,0,0,0,0],[0,0.5,0.5,0,0,0,0],[0,0,0.5,0.5,0,0,0],[0,0,0,0.5,0.5,0,0],[0,0,0,0,0.5,0.5,0],[0,0,0,0,0,0.5,0.5]])\n",
    "B = np.array([GMM(means,covs, weights) for i in np.arange(6)])\n",
    "\n",
    "\n",
    "mc = MarkovChain(q,A)\n",
    "hmm = HMM(mc, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\ncalcabc\n"
     ]
    }
   ],
   "source": [
    "res = hmm.baum_welch(obs,10)\n",
    "\"\"\"\n",
    "res = hmm.baum_welch(obs,20)\n",
    "print(res[0])\n",
    "print()\n",
    "print(res[1])\n",
    "print()\n",
    "print(res[2][0])\n",
    "print()\n",
    "print(res[2][1])\n",
    "print()\n",
    "print(res[2][2])\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save('q0.npy', res[0])\n",
    "save('A0.npy', res[1])\n",
    "save('w0.npy', res[2][0])\n",
    "save('mu0.npy', res[2][1])\n",
    "save('cov0.npy', res[2][2])"
   ]
  }
 ]
}